<!DOCTYPE html> 
<link rel="stylesheet" href="https://cdn.rawgit.com/Chalarangelo/mini.css/v3.0.1/dist/mini-default.min.css">
<meta name="viewport" content="width=device-width, initial-scale=1">
<html>
<head>
<style>
div {margin: auto;
  width: 40%;
  min-width:300px;
}

</style>
<title>Mayo Clinic | Wenchao Cao</title>
<ul>
<li class="current menu0"><a href='https://wenchao320.github.io/index.html'>About</a></li>
<li class="menu1"><a href='https://wenchao320.github.io/mayo.html'>Mayo Clinic</a></li>
<li class="menu2"><a href='https://wenchao320.github.io/upenn.html'>UPenn</a></li>
<li class="menu3"><a href='https://wenchao320.github.io/research.html'>PhD Research</a></li>
<li class="menu4"><a href='https://wenchao320.github.io/courses.html'>Courses</a></li>
<li class="menu5"><a href='https://wenchao320.github.io/contact.html'>Contact</a></li>
</ul>
</head>

<div>
<h1>Mayo Clinic </h1>
<p style="text-align: left;">My role at Mayo Clinic is dedicated to harnessing the power of AI to enhance the clinical usability of CT images. Within this domain, we encounter specific challenges that require careful consideration:
<ol>
<li>The efficacy of image processing often thrives when applied directly to raw data. Unfortunately, access to raw data is not always feasible. As a result, we focus on image domain algorithms for successful deployment in clinical practice.</li>

<li>While larger datasets typically enhance model generalizability, relying solely on models trained on extensive datasets may not yield optimal results for individual cases. This is due to various factors, including varying imaging protocols, patient conditions, and reconstruction kernels, which can lead to deviations from the training data distribution, thereby impacting the performance of trained models. </li>
</ol> 
Rather than attempting to amass large datasets, our strategy focuses on developing flexible methods that can accommodate diverse data. This allows us to efficiently adapt our models as needed.
  </p>
  
<h2>Self-supervised CT image denoising </h2>
<figure style="text-align: center;">
  <img style="margin-right: auto; margin-left: auto; display: block;" src="https://lh3.googleusercontent.com/pw/AIL4fc-KMI14wzBhgW7fuo7gEduokOrXWn-hheX4SCiEnYga5WsCutAVTcwsMMoDipr4hDBuML-EHHng9QW4gHLX2aMmj3olzpns52AzRf5tX8cxUsfArDpejU2ecNsf0XyHRsJQeVN01hJofXMlHTfKppeIMrs1y24tgrSnmXCt7egolk4F6NfDaOujPHK6_AvAJfTRwTJi8GJxrvaLHx5ZP-M7KgndOv4d5BuqD6M3cZR6hu-NnHcgGoo_8ssXYC3ive8U8pTmujqUmbtXAy2BJtL7TG1lrEMjq76wQXClv26WtzG1d1BE0Zd-ApsR9t3d4dGHGbuO22UfqcPM1SvbIuTbh4YaNZwqeTnMIPLn9vUCArBMDv5sLdMvr5ov76IA8smIACEpIZsn8xBdKD81iDjGKY6gIihcpdGARRREVgJuevuZRUirb9TA6U5PbVgLeKdBfDmm9LWXYWrUKLmaOcHoh4qUQ2Qa90EvdaGjEp5yMQBIdJWfvBR8pwYNvUprP4yrqdI1qO_W2JVieL9YnUOjQ00ZQVB-WcaVzp0zwhPU7bpQSrTWqqrtV29bLdXXQhtDzOe7DMDXlKMIUOBoEPs0At8KbZukAiXiBmgy9m4q7Cx0zx2Bm6RTZ16ELZVmaVq1WeB2lXn8wkXFrJVJ_Y-U-ihQ8JBY1oNMs4EfhYHbH8w5bmYLMeo7YqloeXIKKvss-Zo4kRDQm1xxe9IqN7VSlZCb-MInp8SSYv3pepl41lHn9lQgSB00pjiouI7URnQQW-5t_DolhL-hn9iZOAGYrOYH8JD6fMYg-5LtrDHT7UzBv2NpcarD7GCBpmrxqme2N1gZhrfaFDZOEo-lH_xvn-rDuB5_6dQDoyHJ98XHkw-a_uJoU9hKPSx0nmOmSdV-ujifIetkefD_YI4POIdGHWkFnGYtjVftLyFST5eb0inBHQWC4f55fRIdzKM=w767-h857-s-no?authuser=0" />
  <figcaption>Schematic outlining the self-supervised CT denoising framework. </figcaption>
    </figure>
<p style="text-align: left;">In this research, we address the critical issue of noise in CT imaging. Traditional methods for CT image denoising are hindered by the lack of suitable paired data for the supervised training of deep-learning models. To overcome this limitation, we introduce a self-supervised learning approach that utilizes unlabeled clinical images. Our method employs a two-phase data extraction and model optimization pipeline, leveraging regions of uniform signal intensity to characterize local noise properties. We tested this framework on both a private Mayo Clinic dataset and the public TCIA Pancreas-CT dataset, demonstrating a remarkable 87% noise reduction in low-dose CT images while maintaining anatomical details. Furthermore, our method outperformed conventional denoising models in quantitative comparisons, highlighting its potential as a robust and versatile tool for enhancing CT image quality.</p>
  
<h2>Deep Convolutional-neural-network-based Metal Artifact Reduction for CT-guided Interventional Oncology Procedures (MARIO)</h2>
<figure style="text-align: center;">
  <img style="margin-right: auto; margin-left: auto; display: block;" src="https://lh3.googleusercontent.com/pw/AIL4fc8pAP8n6cBZuIFY53S--GDcbVaNJCEaEKyQSyricmwt43gDdRHKDWZlv-MdFWTgZGzrvfLpGeFSHLV1246uEiawSwiH4FdUwEh4WydJiviiHRKqi6TXYrKMxlBRt2DTlKrazLncrRKuO_nW27wNdRY5NFyCju2YIJe3yz0NqmC117N76LmEsx_a6yb-514P5vq3xSvDFNLFSh7n-MEEJ0UJxjOEOEJlJL72hcogyxqItDQkNR-IpMIWQwaB5xq5wKG8karOeoYEvT9Y8px4McmieCshfCg7FWDEXbCSTq8pEu2495nqvVVf5moWeSAg4YPNUZyryktAZhv0oKr3gPNRg5EHXmxMrgQxubyTIy93nK4PvTRquT8wPE4-2Iz6nKaFau9-5rwlqlKQ-PYV9_qmGDN_TQP1eVdyp84eWqkn77mZXuQ9MzJcrmojGiK1lquDduJfuS4Epz-m3Q22JjyXb3az8y7rFfM1sYAS_Lfr4zaiCzvufsNxsRJU6atKB8CCWlPCefOdWFObhFIWurRQvuC-S6b33R-odfvYJEJxjxL9PFng9XCClVrTTH4nUVdzwOHvdIcqlVP9br3K9K-B8F1AJP1F_oEWLTKouhLxnnviDKms07CCWFjt99a3b6XVdzFVfDJ_L0Un_fdU0hNz0CkHq3DklFHKvQxJSR-Rsut6EOHRb6banJ-Pdp-OZO5ZguSuXgJKeem7G0DbnegvPrVL1six2v5qw_GtDuNguviHMiMSYRToS1NovZYDKRUxN_3-S8uAY1UXqDMYbYkQhZslP_Bm62RS0I_88U4eAU8JP5ozeViLAX0Uj8b6iTLiT2YhtmfAzEal9Z3eAcvnJlMt1LYqsHZLOJyeE9eLkj1DysZ8pOUMVtKJgsBzWS0tpYjBj-VBuIdqVbn0pbe1Jb98BnfMTJiPajnL6URYcC_wUV2AZi-Iw0hVO6E=w1565-h857-s-no?authuser=0" />
  <figcaption>Schematic of MARIO framework for generating paired data suitable for optimizing a deep learning model to perform metal artifact reduction. </figcaption>
    </figure>
<p style="text-align: left;">In this study, we tackle the challenge of metal-induced artifacts in CT images during interventional oncology procedures, which can hinder accurate probe placement and compromise the visibility of tissues. Our method involves a comprehensive framework for simulating and reducing metal artifacts caused by cryoablation probes. We validate this framework using a dataset comprising various probe configurations and apply it to real patient CT images. A blinded review by experienced radiologists demonstrates a significant improvement in multiple aspects of image quality, including iceball conspicuity and overall metal artifact reduction, affirming the effectiveness of our algorithm. This innovative image-based approach has the potential to enhance the precision and success of CT-guided interventional oncology procedures.</p>
  
<p><small>Lai Z., Li L., <strong>Cao W.</strong> "<a href="https://ieeexplore.ieee.org/abstract/document/9624386">Metal artifact reduction with deep learning based spectral CT</a>" 2021 14th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI). </small></p>
<footer>
<p class="copy">Wenchao Cao (曹文超) &copy; 2023</p>

</footer></div>
